# ml/model_utils.py

import joblib
from janome.tokenizer import Tokenizer
import numpy as np

# ------------------------------
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
# ------------------------------
model_data = joblib.load("models/senryu_genre_model.joblib")

vectorizer = model_data["vectorizer"]
weights = model_data["weights"]      # shape: (n_classes, vocab)
bias = model_data["bias"]            # shape: (n_classes,)
label_list = model_data["label_list"]

# ------------------------------
# tokenizer
# ------------------------------
tokenizer = Tokenizer()

def tokenize(text):
    tokens = []
    for token in tokenizer.tokenize(text):
        pos = token.part_of_speech.split(",")[0]
        if pos in ["åè©", "å‹•è©", "å½¢å®¹è©", "å‰¯è©"]:
            tokens.append(token.base_form)
    return " ".join(tokens)

# ------------------------------
# ã‚¸ãƒ£ãƒ³ãƒ«äºˆæ¸¬ï¼ˆç¢ºèªç”¨ printä»˜ãï¼‰
# ------------------------------
def predict_genre(senryu_text: str) -> int:
    parsed = tokenize(senryu_text)
    vec = vectorizer.transform([parsed])
    print("ğŸ”¹ TF-IDF ãƒ™ã‚¯ãƒˆãƒ«åŒ–æˆåŠŸ:", vec.shape)

    scores = vec @ weights.T + bias
    print("ğŸ”¹ ã‚¹ã‚³ã‚¢è¨ˆç®—æˆåŠŸ:", scores.shape)

    # numpy å¤‰æ›ã¯ä¸è¦
    scores = scores[0]
    print("ğŸ”¹ ã‚¹ã‚³ã‚¢é…åˆ—:", scores)

    best_index = np.argmax(scores)
    predicted_genre = label_list[best_index]
    print(f"ğŸ”¹ å…¥åŠ›: ã€{senryu_text}ã€ â†’ æ¨å®šã‚¸ãƒ£ãƒ³ãƒ«ID: {predicted_genre}")

    return int(predicted_genre)
